=========
Scripting
=========

Before scripting
~~~~~~~~~~~~~~~~

1. Get Globus ID
----------------
1. Follow only step 1 of `instructions here <https://docs.globus.org/how-to/get-started/>`_ to get a Globus account.
2. Ensure that your ``globus ID`` is linked with your institutional ID in your globus account:
    a. Log into `globus.org <www.globus.org>`_
    b. Click on ``Account`` on the left hand pane
    c. Select the ``Identities`` tab in the window that opens up
    d. You should see (at least these) two identities:

       i. One from your home institution (that is listed as ``primary`` with a crown)
       ii. Globus ID (your_username@globusid.org)

    e. If you do not see the ``Globus ID``, click on ``Link another identity``. Select ``Globus ID`` and link this ID.

2. Register at DataFed
----------------------
1. Once you have a Globus ID, visit the `DataFed web portal <https://datafed.ornl.gov>`_.
2. Click on the ``Log in / Register`` button on the top right of the page.
3. Follow the steps to register yourself with DataFed.
4. Though you can log into the DataFed web portal with your institution's credentials, you will need the username and password you set up during your registration for scripting.

3. Installing DataFed
---------------------
For this section, we will assume that you intend to use the Client CLI on a
remote machine such as an institutional cluster or HPC and that this machine has one or more Globus endpoints that can be used by all uesrs.

1. Load any python 3.5+ module or any conda environment that you intend to use.
2. Install the datafed client package via:
   ``pip install --user datafed``
3. Try typing ``datafed`` to access the DataFed CLI.
   If you encounter errors stating that datafed was an unknown command, you would need to add DataFed to your path.
   a. First, you would need to find where datafed was installed. For example, in the case of NERSC's Cori machine, datafed was installed at ``~/.local/cori/3.7-anaconda-2019.10/bin``.
   b. Next, add DataFed to the path via ``PATH=$PATH:path/to/datafed/here``. Though this works, this addition to the path is only valid for this shell session.
   It is recommended to add the path to your ``bashrc`` or ``rc`` such that datafed is loaded everytime you log in.

4. Setting up DataFed
---------------------
1. Type ``datafed setup`` into the shell. It will prompt you for your username and password.
2. Enter the credentials you set up when registering for an account on DataFed
3. Identify the Globus endpoint(s) attached to this machine from the user guide for the machine you are using.
   For example, the following endpoint can be used when using OLCF's Summit supercomputer: ``olcf#dtn``
4. Now, add this end point as your default endpoint via:
   ``datafed ep default set endpoint_name_here``

This concludes the one-time setup necessary to get started with scripting using DataFed.
You may use the interactive DataFed CLI or the Python package at this point.

Shell scripting
~~~~~~~~~~~~~~~

Creating a record in data repository

.. code:: bash

    > datafed data create \
    --alias "record_from_nersc" \ # Optional argument
    --description "Data and metadata created at NERSC" \ # Optional argument
    --metadata-file ./nersc_md.json \ # Optional argument
    "First record created at NERSC using DataFed CLI" # Title is required though

    ID:            d/31030353
    Alias:         record_from_nersc
    Title:         First record created at NERSC using DataFed CLI
    Data Size:     0
    Data Repo ID:  repo/cades-cnms
    Source:        (none)
    Owner:         somnaths
    Creator:       somnaths
    Created:       11/25/2020,08:04
    Updated:       11/25/2020,08:04
    Description:   Data and metadata created at NERSC

Checking to make sure record was created

.. code:: bash

    > datafed ls

    1. d/31027390   (record_from_alcf)    First record created at ALCF
    2. d/31030353   (record_from_nersc)   First record created at NERSC using DataFed CLI
    3. d/29426537                         from_olcf

Putting raw data into record (via Globus)

.. code:: bash

    > datafed data put \
      --wait \ # optional - wait until Globus transfer completes
      "record_from_nersc" \ # optional - (unique) alias of record
      ./nersc_data.txt # path to data

    Task ID:             task/31030394
    Type:                Data Put
    Status:              Succeeded
    Started:             11/25/2020,08:05
    Updated:             11/25/2020,08:05

Checking to make sure data was uploaded

.. code:: bash

    > datafed data view "record_from_nersc"

    ID:            d/31030353
    Alias:         record_from_nersc
    Title:         First record created at NERSC using DataFed CLI
    Tags:          (none)
    Data Size:     37.0 B
    Data Repo ID:  repo/cades-cnms
    Source:        nersc#dtn/global/u2/s/somnaths/nersc_data.txt
    Extension:     (auto)
    Owner:         somnaths
    Creator:       somnaths
    Created:       11/25/2020,08:04
    Updated:       11/25/2020,08:05
    Description:   Data and metadata created at NERSC

(Preparing to) get data from repository:

.. code:: bash

    > datafed data view d/10314975

    ID:            d/10314975
    Alias:         cln_b_1_beline_0001
    Title:         CLN_B_1_BEline_0001
    Tags:          (none)
    Data Size:     25.7 MB
    Data Repo ID:  repo/cades-cnms
    Source:        57230a10-7ba2-11e7-8c3b-22000b9923ef/lustre/or-hydra/cades-ccsd/syz/pycroscopy_ensemble/be_sho/Nanophase_Done/CLN_B_1_BEline_0001.h5
    Extension:     (auto)
    Owner:         somnaths
    Creator:       somnaths
    Created:       11/01/2019,19:54
    Updated:       11/15/2019,20:31
    Description:   (none)

Showing that the file we want to download / get doesn't already exist:

.. code:: bash

    > ls -hlt
    total 28M
    -rw-rw---- 1 somnaths somnaths   40 Nov 25 07:58 nersc_md.json
    -rw-r--r-- 1 somnaths somnaths 400K Nov  3 13:36 Translation_compiled.html
    -rw-r--r-- 1 somnaths somnaths 1.9M Nov  3 13:30 image_02.mat
    -rw-rw---- 1 somnaths somnaths   37 Nov  3 11:41 nersc_data.txt

Initiating the the ``get`` command:

.. code:: bash

    > datafed data get \
      --wait \ # optional - wait for Globus transfer to complete
      d/10314975 \ # ID of data record
      . # Where to put it in local file system

    > ls -hlt
    total 28M
    -rw-r--r-- 1 somnaths somnaths  26M Nov 25 08:08 10314975.h5
    -rw-rw---- 1 somnaths somnaths   40 Nov 25 07:58 nersc_md.json
    -rw-r--r-- 1 somnaths somnaths 400K Nov  3 13:36 Translation_compiled.html
    -rw-r--r-- 1 somnaths somnaths 1.9M Nov  3 13:30 image_02.mat
    -rw-rw---- 1 somnaths somnaths   37 Nov  3 11:41 nersc_data.txt


Python scripting
~~~~~~~~~~~~~~~~
Scripting guide here.