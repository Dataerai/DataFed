============
Introduction
============

DataFed is a *federated* and *scalable* scientific data management and collaboration system that
addresses the critical need for holistic and FAIR-principled "big data" handling within, and across,
scientific domains and facilities - with the goal of enhancing the *productivity* and *reproducibility*
of data-oriented scientific research.

[WHAT IS SDMS, WHY IS IT NEEDED]

DataFed provides many of the same benefits of typical scientific data management systems such as
storage and access to structured and unstructured heterogeneous raw data with access control,
metadata and provenance capture, and metadata indexing and search; however, DataFed differs from
these systems in several significant areas:

- DataFed is **general purpose**. DataFed is domain- and methodology-neutral in that it does not require
  users to utilize pre-defined data formats or processes - yet, despite this, DataFed provides powerful
  domain-specific metadata indexing and query capabilities augmented by user/community defined schemas.

- DataFed supports the **pre-publication data lifecycle**.

- DataFed is **Scalable**. Datafed was designed to easily scale-out across multiple/many organizations
  and facilities by relying on federated identity technology and a common access control mechanism;
  however, individual organizations are still able to manage their own data storage resources and policies.
  In contrast, most existing SDMS products either cannot span organizations at all, or rely on virtual
  organization (VO) technologies that are highly labor-intensive to scale beyond a few organizations.

- DataFed **understands big data**. DataFed was design from the start to support "big data" and
  the often complex environments in which such data is created and processed. Many existing SDMS products
  rely on tightly-coupled file systems or HTTP/S for moving data; however, DataFed utilizes Globus (GridFTP)
  for data transfer between facilities because it is the defacto standard for high performance movement
  of very large data sets (Petabyte scale) between government-funded user facilities (DoE), research
  universities, and commercial cloud computing services.

- DataFed focuses on providing high quality, uniform, and easy-to-use data management services
  and does not overreach by bundling complementary features such as instrument control, workflow
  processing, or data analytics that are better served by dedicated application-specific tools. However,
  DataFed does provide application programming interfaces (APIs) to allow other services or applications
  to be utilize DataFed's data management capabilities.


DataFed directly benefits both individual researchers and teams of geographically dispersed collaborators
who need to capture, manage, share, and access scientific data from any of the experimental, observational,
compute, or analytics resources within the Department of Energy's national laboratory network.

.. image:: /_static/simplified_architecture.png

ing, or are local to, multiple user facilities
at Department of Energy national laboratories

(experimental, observational, compute, or analytics),

The key benefits of DataFed for 

discovery, access, and sharing

FAIR

Data Backplane

Scientific Data Life Cycle

Domain Agnostic

Foundation for Domain-Specific Applications

Cross-Facility Research

Database View (logical vs physical)

Metadata and Provenance

Big Data Support
